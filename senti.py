import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import json
from rapidfuzz import fuzz, process  # ‚úÖ ‡πÉ‡∏ä‡πâ rapidfuzz ‡πÅ‡∏ó‡∏ô fuzzywuzzy (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤)

# st.title("üç≤ Thai Food Review Sentiment Analysis (Dataset + Model Fallback + Fuzzy Match)")
st.title("üç≤ Thai Food Review ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡∏û‡∏ß‡∏Å‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πâ‡∏á‡πÑ‡∏î‡πâ‡πÅ‡∏î‡∏Å‡∏≠‡∏≤‡∏´‡∏≤‡∏£")
# st.write("‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dataset ‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• FlukeTJ/distilbert-base-thai-sentiment")
st.write("‡∏à‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏ó‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏û‡∏ß‡∏Å‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πâ‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏•‡∏≤‡∏¢")
# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• fallback
MODEL_NAME = "FlukeTJ/distilbert-base-thai-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

labels = ["negative(‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Å‡∏¢‡πå‡∏•‡∏ö) üòû", "neutral(‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Å‡∏¢‡πå‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á) üòê", "positive(‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Å‡∏¢‡πå‡∏ö‡∏ß‡∏Å) üòä"]
label2id = {"negative": 0, "neutral": 1, "positive": 2}

# ‡πÇ‡∏´‡∏•‡∏î dataset
with open("thai_food_reviews.json", "r", encoding="utf-8") as f:
    dataset = json.load(f)

# normalize text
def normalize(text: str):
    return text.strip().lower().replace(" ", "")

# ‡πÅ‡∏õ‡∏•‡∏á dataset ‡πÄ‡∏õ‡πá‡∏ô dict
dataset_dict = {normalize(item["text"]): label2id[item["label"]] for item in dataset}
sorted_keywords = sorted(dataset_dict.keys(), key=len, reverse=True)  # keyword ‡∏¢‡∏≤‡∏ß‡∏Å‡πà‡∏≠‡∏ô

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ä‡πá‡∏Ñ keyword + fuzzy match
def find_keyword_match(input_text, threshold=80):
    norm_input = normalize(input_text)

    # 1) ‡πÄ‡∏ä‡πá‡∏Ñ exact match (substring)
    for kw in sorted_keywords:
        if kw in norm_input:
            return dataset_dict[kw], kw, 100

    # 2) ‡πÉ‡∏ä‡πâ fuzzy match
    match, score, _ = process.extractOne(norm_input, dataset_dict.keys(), scorer=fuzz.ratio)
    if score >= threshold:
        return dataset_dict[match], match, score

    return None, None, None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏≤ example
def find_similar_examples(input_text, top_k=5):
    norm_input = normalize(input_text)
    matches = process.extract(norm_input, dataset_dict.keys(), scorer=fuzz.partial_ratio, limit=top_k)
    return [m[0] for m in matches]

# Input ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
user_input = st.text_input("‡∏õ‡πâ‡∏≠‡∏ô‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:")

if user_input:
    # 1) ‡∏ï‡∏£‡∏ß‡∏à dataset ‡∏Å‡πà‡∏≠‡∏ô
    pred_label, matched_kw, score = find_keyword_match(user_input)

    if pred_label is not None:
        confidence = 100.0 if score == 100 else score
        # st.write(f"‚úÖ ‡∏û‡∏ö‡πÉ‡∏ô dataset (match: '{matched_kw}', similarity: {score:.2f}%)")
        st.write(f"‚úÖ ‡∏û‡∏ö‡πÉ‡∏ô dataset 
    else:
        # 2) ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‚Üí ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• FlukeTJ/distilbert-base-thai-sentiment
        inputs = tokenizer(user_input, return_tensors="pt", truncation=True, padding=True)
        inputs.pop("token_type_ids", None)
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
            pred_label = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_label].item() * 100
        st.write("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö keyword ‚Üí ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• FlukeTJ/distilbert-base-thai-sentiment ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    st.write(f"**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:** {labels[pred_label]}")
    if confidence < 60:
        st.warning(f"‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ï‡πà‡∏≥ ({confidence:.2f}%) ‚Üí ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥")
    else:
        st.write(f"**‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö:** {confidence:.2f}%")

    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
    # st.write("üîé ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏à‡∏≤‡∏Å dataset ‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô:")
    # examples = find_similar_examples(user_input)
    # for e in examples:
    #     st.write(f"- {e}")

